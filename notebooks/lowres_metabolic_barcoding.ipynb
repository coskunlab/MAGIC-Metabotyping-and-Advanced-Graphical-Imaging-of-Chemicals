{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3338b08f-51bc-418e-b347-a50c59db359a",
   "metadata": {},
   "source": [
    "### Metabolic Barcoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39131c1e-8038-4f67-8f1c-118430c3f973",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import scanpy as sc\n",
    "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler \n",
    "import numpy as np\n",
    "\n",
    "base_dir = r\"..\\results\\high_low_no\"\n",
    "adata = sc.read_h5ad(os.path.join(base_dir, \"combined_adata_leiden_merged.h5ad\"))\n",
    "adata.X = MaxAbsScaler().fit_transform(adata.X.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e0f2b7-307e-4808-a313-0cb4a150cae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map cluster to phenotype\n",
    "phenotype_map = {\n",
    "    \"0\": \"Neurons\",\n",
    "    \"1\": \"Neurons\",\n",
    "    \"2\": \"Astrocytes\",\n",
    "    \"3\": \"Neurons\",\n",
    "    \"4\": \"Neurons\",\n",
    "    \"5\": \"Oligodendrocytes\",\n",
    "    \"6\": \"Endothelial cells\",\n",
    "    \"7\": \"Neurons\",\n",
    "    \"8\": \"Endothelial cells\",\n",
    "    \"9\": \"Neurons\"\n",
    "} \n",
    "\n",
    "adata.obs['cell_phenotype'] = adata.obs['leiden_merged'].map(phenotype_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6cb006-a436-4b3b-8ea8-c6cd9959dd00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "\n",
    "# === Setup ===\n",
    "output_dir = r\"results\\high_low_no\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Ensure 'msi_aligned_labels' is categorical\n",
    "adata.obs['cell_phenotype'] = adata.obs['cell_phenotype'].astype('category')\n",
    "\n",
    "# Generate distinct colors using seaborn\n",
    "phenotype_colors = {\n",
    "    \"Astrocytes\": \"#1f77b4\",         # blue\n",
    "    \"Oligodendrocytes\": \"#2ca02c\",   # green\n",
    "    \"Neurons\": \"#d62728\",            # red\n",
    "    \"Microglia\": \"#9467bd\",          # purple\n",
    "    \"Endothelial cells\": \"#e377c2\",  # pink\n",
    "}\n",
    "\n",
    "# === Plot for each condition separately ===\n",
    "for condition in ['High', 'Low', 'No']:\n",
    "    # Subset\n",
    "    adata_temp = adata[adata.obs['condition'] == condition].copy()\n",
    "\n",
    "    # Create plotting DataFrame\n",
    "    plot_df = adata_temp.obs[['x_centroid', 'y_centroid', 'cell_phenotype']].copy()\n",
    "    plot_df = plot_df.dropna(subset=['cell_phenotype'])\n",
    "    plot_df['cell_phenotype'] = plot_df['cell_phenotype'].astype(str)\n",
    "    plot_df['color'] = plot_df['cell_phenotype'].map(phenotype_colors)\n",
    "    plot_df = plot_df.dropna(subset=['color'])\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.scatter(\n",
    "        plot_df['x_centroid'],\n",
    "        plot_df['y_centroid'],\n",
    "        c=plot_df['color'].values,\n",
    "        s=1,\n",
    "        linewidth=0,\n",
    "        alpha=1.0\n",
    "    )\n",
    "    ax.set_aspect('equal')\n",
    "    ax.axis('off')\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    # Add legend (optional)\n",
    "    handles = [\n",
    "        mpatches.Patch(color=color, label=label)\n",
    "        for label, color in phenotype_colors.items()\n",
    "        if label in plot_df['cell_phenotype'].values\n",
    "    ]\n",
    "    ax.legend(handles=handles, loc='center left', bbox_to_anchor=(1, 0.5), fontsize=6, title=\"Cell Phenotype\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save\n",
    "    save_path = os.path.join(output_dir, f\"{condition.lower()}_cell_phenotype_spatial_map.png\")\n",
    "    plt.savefig(save_path, dpi=600, bbox_inches='tight', pad_inches=0.0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ab4d25-d0a2-440c-a96c-67f29dd30c93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import Delaunay\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "# Step 1: Define Graph Construction\n",
    "def create_graph(adata, distance_threshold=None):\n",
    "    \"\"\"\n",
    "    Create a graph efficiently using KDTree for distance thresholding.\n",
    "    \n",
    "    Parameters:\n",
    "    - adata: AnnData object containing centroids in .obs\n",
    "    - distance_threshold: Maximum distance for connecting two nodes\n",
    "    \n",
    "    Returns:\n",
    "    - G: NetworkX graph\n",
    "    - pos: Dictionary of node positions\n",
    "    \"\"\"\n",
    "    # Extract centroids\n",
    "    centroids = adata.obs[['x_centroid', 'y_centroid']].values\n",
    "    \n",
    "    # Create graph\n",
    "    G = nx.Graph()\n",
    "    for i, (x, y) in enumerate(centroids):\n",
    "        G.add_node(i, pos=(x, y))  # Add nodes with positions\n",
    "    \n",
    "    if distance_threshold:\n",
    "        # Use KDTree for efficient neighbor search\n",
    "        tree = cKDTree(centroids)\n",
    "        pairs = tree.query_pairs(r=distance_threshold)\n",
    "        G.add_edges_from(pairs)  # Add edges directly from KDTree output\n",
    "    else:\n",
    "        # Use Delaunay triangulation if no threshold is provided\n",
    "        tri = Delaunay(centroids)\n",
    "        for simplex in tri.simplices:\n",
    "            G.add_edge(simplex[0], simplex[1])\n",
    "            G.add_edge(simplex[1], simplex[2])\n",
    "            G.add_edge(simplex[2], simplex[0])\n",
    "    \n",
    "    # Extract positions\n",
    "    pos = nx.get_node_attributes(G, 'pos')\n",
    "    \n",
    "    return G, pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483b5eca-6fe2-4109-90d2-6e86b8d4fb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "def prepare_graph_data_cell_type(msi_adata, distance_threshold=10):\n",
    "    \"\"\"\n",
    "    Create separate PyG graphs for WT and PS19, using lipid features,\n",
    "    excluding cells labeled as 'Others' in 'cell_phenotype'.\n",
    "\n",
    "    Parameters:\n",
    "    - msi_adata: AnnData object with 'condition' and 'cell_phenotype' in .obs\n",
    "    - distance_threshold: max distance for graph edges\n",
    "\n",
    "    Returns:\n",
    "    - graph_data_dict: {condition: PyG Data}\n",
    "    - label_encoder: fitted LabelEncoder for consistent labels\n",
    "    \"\"\"\n",
    "    graph_data_dict = {}\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    # === Global label fitting on all valid cells (WT + PS19, excluding 'Others') ===\n",
    "    valid_mask = msi_adata.obs['cell_phenotype'] != 'Others'\n",
    "    label_encoder.fit(msi_adata.obs.loc[valid_mask, 'cell_phenotype'])\n",
    "\n",
    "    for condition in ['High', 'Low', 'No']:\n",
    "        adata_cond = msi_adata[\n",
    "            (msi_adata.obs['condition'] == condition) &\n",
    "            (msi_adata.obs['cell_phenotype'] != 'Others')\n",
    "        ].copy()\n",
    "\n",
    "        if adata_cond.n_obs == 0:\n",
    "            continue\n",
    "\n",
    "        # === Extract lipid features\n",
    "        lipid_channels = [c for c in adata_cond.var_names if c.startswith(\"mz_\")]\n",
    "        lipid_X = adata_cond[:, lipid_channels].X\n",
    "        lipid_X = lipid_X.toarray() if hasattr(lipid_X, 'toarray') else lipid_X\n",
    "        features = torch.tensor(lipid_X, dtype=torch.float)\n",
    "\n",
    "        # === Encode labels\n",
    "        labels = torch.tensor(\n",
    "            label_encoder.transform(adata_cond.obs['cell_phenotype']),\n",
    "            dtype=torch.long\n",
    "        )\n",
    "\n",
    "        # === Build edges using cKDTree\n",
    "        centroids = adata_cond.obs[['x_centroid', 'y_centroid']].values\n",
    "        tree = cKDTree(centroids)\n",
    "        pairs = tree.query_pairs(r=distance_threshold)\n",
    "\n",
    "        G = nx.Graph()\n",
    "        for i, (x, y) in enumerate(centroids):\n",
    "            G.add_node(i, pos=(x, y))\n",
    "        G.add_edges_from(pairs)\n",
    "\n",
    "        edge_index = torch.tensor(list(G.edges), dtype=torch.long).t().contiguous()\n",
    "        edge_index = torch.cat([edge_index, edge_index.flip(0)], dim=1)  # undirected\n",
    "\n",
    "        # === Create PyG graph object\n",
    "        graph_data = Data(x=features, edge_index=edge_index, y=labels)\n",
    "        graph_data_dict[f\"{condition}\"] = graph_data\n",
    "\n",
    "    return graph_data_dict, label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e6f70a-753d-4b25-9911-bd0e585ea805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import GCNConv, SAGEConv, GraphConv, GATConv, GINConv\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=2):\n",
    "        \"\"\"\n",
    "        A Graph Neural Network with configurable number of layers.\n",
    "\n",
    "        Parameters:\n",
    "        - in_channels: Number of input features.\n",
    "        - hidden_channels: Number of hidden units in each layer.\n",
    "        - out_channels: Number of output classes.\n",
    "        - num_layers: Total number of layers (default=2).\n",
    "        \"\"\"\n",
    "        super(GNN, self).__init__()\n",
    "        \n",
    "        # Ensure at least 2 layers\n",
    "        assert num_layers >= 2, \"Number of layers must be at least 2.\"\n",
    "\n",
    "        # Create a list to store convolutional layers\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "\n",
    "        # Input layer\n",
    "        self.convs.append(GraphConv(in_channels, hidden_channels))\n",
    "        \n",
    "        # Hidden layers\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(GraphConv(hidden_channels, hidden_channels))\n",
    "        \n",
    "        # Output layer\n",
    "        self.convs.append(GraphConv(hidden_channels, out_channels))\n",
    "\n",
    "    def forward(self, x, edge_index, **kwargs):\n",
    "        # Pass through all convolutional layers\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x = conv(x, edge_index)\n",
    "            if i < len(self.convs) - 1:  # Apply activation except for the last layer\n",
    "                x = F.relu(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Save model function\n",
    "def save_model(model, optimizer, epoch, path=\"gnn_model.pth\"):\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'epoch': epoch\n",
    "    }, path)\n",
    "    print(f\"Model saved to {path}\")\n",
    "\n",
    "# Load model function\n",
    "def load_model(path=\"gnn_model.pth\"):\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    print(f\"Model loaded from {path}, starting at epoch {epoch}\")\n",
    "    return epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b87e78e-a0ea-45bc-bb3f-a627a0e68c50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# === Reproducibility ===\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# === Prepare single-graph data ===\n",
    "graph_data_dict, label_encoder = prepare_graph_data_cell_type(adata, distance_threshold=10)  # uses 'cell_phenotype'\n",
    "graphs = list(graph_data_dict.values())\n",
    "full_batch = Batch.from_data_list(graphs)\n",
    "y_all = full_batch.y.cpu().numpy()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "save_dir = r\"..\\results\\high_low_no\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# === K-fold setup ===\n",
    "k = 3\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=seed)\n",
    "results = []\n",
    "\n",
    "# === Cross-validation loop ===\n",
    "for fold, (train_val_idx, test_idx) in enumerate(skf.split(np.zeros(len(y_all)), y_all)):\n",
    "    print(f\"\\n[Fold {fold+1}/{k}]\")\n",
    "\n",
    "    # Split train/val\n",
    "    val_split = int(0.15 * len(train_val_idx))\n",
    "    np.random.shuffle(train_val_idx)\n",
    "    val_idx = train_val_idx[:val_split]\n",
    "    train_idx = train_val_idx[val_split:]\n",
    "\n",
    "    # Assign masks\n",
    "    full_batch.train_mask = torch.zeros(len(y_all), dtype=torch.bool)\n",
    "    full_batch.val_mask = torch.zeros(len(y_all), dtype=torch.bool)\n",
    "    full_batch.test_mask = torch.zeros(len(y_all), dtype=torch.bool)\n",
    "    full_batch.train_mask[train_idx] = True\n",
    "    full_batch.val_mask[val_idx] = True\n",
    "    full_batch.test_mask[test_idx] = True\n",
    "\n",
    "    # Save batch for evaluation\n",
    "    torch.save(full_batch.cpu(), f\"{save_dir}/fold_{fold+1}_graph.pt\")\n",
    "\n",
    "    # Wrap in DataLoader\n",
    "    loader = DataLoader([full_batch], batch_size=1, shuffle=False)\n",
    "\n",
    "    # === Model setup ===\n",
    "    model = GNN(\n",
    "        in_channels=full_batch.num_node_features,\n",
    "        hidden_channels=64,\n",
    "        out_channels=len(label_encoder.classes_),\n",
    "        num_layers=5\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    patience = 200\n",
    "\n",
    "    # === Training loop ===\n",
    "    for epoch in range(2000):\n",
    "        model.train()\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(batch.x, batch.edge_index)\n",
    "            loss = criterion(out[batch.train_mask], batch.y[batch.train_mask])\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "        # === Validation and early stopping ===\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in loader:\n",
    "                batch = batch.to(device)\n",
    "                out = model(batch.x, batch.edge_index)\n",
    "                val_loss = criterion(out[batch.val_mask], batch.y[batch.val_mask])\n",
    "                pred = out.argmax(dim=1)\n",
    "                correct = (pred[batch.test_mask] == batch.y[batch.test_mask]).sum().item()\n",
    "                total = batch.test_mask.sum().item()\n",
    "                test_acc = correct / total if total > 0 else 0\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': val_loss,\n",
    "            }, f\"{save_dir}/cell_type_model_fold_{fold+1}_best.pth\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Val Loss: {val_loss:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        'fold': fold + 1,\n",
    "        'best_val_loss': best_val_loss.item(),\n",
    "        'test_accuracy': test_acc\n",
    "    })\n",
    "\n",
    "# === Save CV results ===\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(f\"{save_dir}/cell_type_crossval_results.csv\", index=False)\n",
    "print(\"Cross-validation completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61cfa5b-cb31-447c-9784-649c03867413",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from torch_geometric.loader import DataLoader\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Parameters ===\n",
    "save_dir = r\"..\\results\\high_low_no\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "hidden_channels = 64\n",
    "num_layers = 5\n",
    "num_folds = 3\n",
    "\n",
    "graph_data_dict, label_encoder = prepare_graph_data_cell_type(adata, distance_threshold=10)\n",
    "graphs = list(graph_data_dict.values())\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "target_names = label_encoder.classes_\n",
    "num_classes = len(target_names)\n",
    "\n",
    "cell_group_color_dict = {\n",
    "    \"Astrocytes\": \"#1f77b4\",         # blue\n",
    "    \"Oligodendrocytes\": \"#2ca02c\",   # green\n",
    "    \"Neurons\": \"#d62728\",            # red\n",
    "    \"Microglia\": \"#9467bd\",          # purple\n",
    "    \"Endothelial cells\": \"#e377c2\",  # pink\n",
    "}\n",
    "\n",
    "# === Evaluation Function ===\n",
    "def evaluate_gnn(model, loader, num_classes):\n",
    "    model.eval()\n",
    "    all_probs, all_preds, all_labels = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            out = model(batch.x, batch.edge_index)\n",
    "            prob = torch.softmax(out, dim=1)\n",
    "            pred = out.argmax(dim=1)\n",
    "\n",
    "            mask = batch.test_mask\n",
    "            all_probs.append(prob[mask].cpu().numpy())\n",
    "            all_preds.append(pred[mask].cpu().numpy())\n",
    "            all_labels.append(batch.y[mask].cpu().numpy())\n",
    "    return np.concatenate(all_preds), np.concatenate(all_labels), np.concatenate(all_probs)\n",
    "\n",
    "# === Run K-Fold Evaluation ===\n",
    "all_auc_dicts = []\n",
    "all_acc_dicts = []\n",
    "\n",
    "for fold_id in range(1, num_folds + 1):\n",
    "    print(f\"\\n=== Evaluating Fold {fold_id} ===\")\n",
    "\n",
    "    model_path = f\"{save_dir}/cell_type_model_fold_{fold_id}_best.pth\"\n",
    "    graph_path = f\"{save_dir}/fold_{fold_id}_graph.pt\"\n",
    "\n",
    "    if not os.path.exists(model_path) or not os.path.exists(graph_path):\n",
    "        print(f\"Skipping fold {fold_id}: missing model or graph.\")\n",
    "        continue\n",
    "\n",
    "    model = GNN(\n",
    "        in_channels=graphs[0].num_node_features,\n",
    "        hidden_channels=hidden_channels,\n",
    "        out_channels=num_classes,\n",
    "        num_layers=num_layers\n",
    "    ).to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device)['model_state_dict'])\n",
    "\n",
    "    graph = torch.load(graph_path)\n",
    "    loader = DataLoader([graph], batch_size=1, shuffle=False)\n",
    "\n",
    "    preds, labels, probs = evaluate_gnn(model, loader, num_classes)\n",
    "\n",
    "    report = classification_report(labels, preds, target_names=target_names, output_dict=True)\n",
    "    accs = {'fold_id': fold_id}\n",
    "    for cname in target_names:\n",
    "        accs[cname] = report[cname]['f1-score']\n",
    "    all_acc_dicts.append(accs)\n",
    "\n",
    "    labels_bin = label_binarize(labels, classes=np.arange(num_classes))\n",
    "    aucs = {'fold_id': fold_id}\n",
    "    for i, cname in enumerate(target_names):\n",
    "        try:\n",
    "            auc = roc_auc_score(labels_bin[:, i], probs[:, i])\n",
    "        except ValueError:\n",
    "            auc = np.nan\n",
    "        aucs[cname] = auc\n",
    "    all_auc_dicts.append(aucs)\n",
    "\n",
    "    # === Print Metrics ===\n",
    "    print(classification_report(labels, preds, target_names=target_names))\n",
    "    print(\"Per-Class AUCs:\")\n",
    "    for cname in target_names:\n",
    "        val = aucs[cname]\n",
    "        print(f\"  {cname}: {val:.4f}\" if not np.isnan(val) else f\"  {cname}: N/A\")\n",
    "\n",
    "# === Save Metrics ===\n",
    "acc_df = pd.DataFrame(all_acc_dicts)\n",
    "auc_df = pd.DataFrame(all_auc_dicts)\n",
    "\n",
    "acc_df.to_csv(f\"{save_dir}/cell_type_per_class_accuracy.csv\", index=False)\n",
    "auc_df.to_csv(f\"{save_dir}/cell_type_per_class_auc.csv\", index=False)\n",
    "print(\"\\n✓ Saved per-class accuracy and AUC CSVs.\")\n",
    "\n",
    "# === Prepare for Boxplots ===\n",
    "def melt_with_group(df, metric_name):\n",
    "    melted = df.melt(id_vars=\"fold_id\", var_name=\"Class\", value_name=metric_name)\n",
    "    melted[\"Group\"] = melted[\"Class\"].map(lambda c: next((g for g in cell_group_color_dict if g in c), \"Others\"))\n",
    "    melted[\"Color\"] = melted[\"Group\"].map(cell_group_color_dict).fillna(\"gray\")\n",
    "    return melted\n",
    "\n",
    "acc_melt = melt_with_group(acc_df, \"Accuracy\")\n",
    "auc_melt = melt_with_group(auc_df, \"AUC\")\n",
    "\n",
    "# === Plotting Function ===\n",
    "def plot_metric(df, metric, filename):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(\n",
    "        data=df,\n",
    "        x=\"Class\",\n",
    "        y=metric,\n",
    "        palette=df.set_index(\"Class\")[\"Color\"].to_dict()\n",
    "    )\n",
    "    \n",
    "    plt.title(f\"{metric} per Cell Type\", fontsize=18)      # Title font size\n",
    "    plt.ylabel(metric, fontsize=16)                        # Y-axis label font size\n",
    "    plt.xlabel(\"Cell Type\", fontsize=16)                   # X-axis label font size\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=16)       # X-tick font size\n",
    "    plt.yticks(fontsize=16)                                # Y-tick font size\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{save_dir}/{filename}.png\", dpi=600)\n",
    "    plt.show()\n",
    "\n",
    "def plot_metric_with_errorbars(df, metric, filename):\n",
    "    # Compute summary stats\n",
    "    summary_df = df.groupby(\"Class\").agg(\n",
    "        mean=(metric, \"mean\"),\n",
    "        std=(metric, \"std\"),\n",
    "        Group=(\"Group\", \"first\"),\n",
    "        Color=(\"Color\", \"first\")\n",
    "    ).reset_index()\n",
    "\n",
    "    # Add dummy hue to trigger custom palette handling\n",
    "    summary_df[\"hue\"] = summary_df[\"Class\"]\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ax = sns.barplot(\n",
    "        data=summary_df,\n",
    "        x=\"Class\",\n",
    "        y=\"mean\",\n",
    "        hue=\"hue\",  # dummy hue just to enable palette per class\n",
    "        palette=summary_df.set_index(\"Class\")[\"Color\"].to_dict(),\n",
    "        errorbar=None  # disable seaborn CI bars\n",
    "    )\n",
    "\n",
    "    # Add error bars manually\n",
    "    for i, row in summary_df.iterrows():\n",
    "        ax.errorbar(\n",
    "            i, row[\"mean\"],\n",
    "            yerr=row[\"std\"],\n",
    "            fmt='none',\n",
    "            ecolor='black',\n",
    "            elinewidth=1.5,\n",
    "            capsize=4\n",
    "        )\n",
    "\n",
    "    # Remove redundant legend if it appears\n",
    "    legend = ax.get_legend()\n",
    "    if legend is not None:\n",
    "        legend.remove()\n",
    "\n",
    "    # Format\n",
    "    plt.title(f\"GNN {metric} per Cell Phenotype\", fontsize=18)\n",
    "    plt.ylabel(metric, fontsize=16)\n",
    "    plt.xlabel(\"Cell Type\", fontsize=16)\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{save_dir}/{filename}_barplot.png\", dpi=600)\n",
    "    plt.show()\n",
    "\n",
    "# === Plot AUC and Accuracy ===\n",
    "plot_metric(acc_melt, \"Accuracy\", f\"cell_type_fold_accuracy_boxplot\")\n",
    "plot_metric(auc_melt, \"AUC\", f\"cell_type_fold_auc_boxplot\")\n",
    "plot_metric_with_errorbars(acc_melt, \"Accuracy\", \"cell_type_fold_accuracy\")\n",
    "plot_metric_with_errorbars(auc_melt, \"AUC\", \"cell_type_fold_auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5258675-da12-482a-aba4-e68c61c19ebe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.explain import Explainer, CaptumExplainer\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Parameters\n",
    "n_folds = 3\n",
    "attr_method = 'IntegratedGradients'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "feature_labels = [c for c in adata.var_names if c.startswith(\"mz_\")]\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "all_scores = {\"all\": [], \"test\": []}\n",
    "\n",
    "def calculate_average_explanations(explainer, batch, mask=None, n_iterations=1):\n",
    "    scores = []\n",
    "    for _ in range(n_iterations):\n",
    "        explanation = explainer(batch.x, batch.edge_index)\n",
    "        node_mask = explanation.node_mask.cpu().detach().numpy()\n",
    "        if mask is not None:\n",
    "            node_mask = node_mask[mask.cpu().numpy()]\n",
    "        scores.append(node_mask.sum(axis=0))\n",
    "    return np.mean(scores, axis=0)\n",
    "\n",
    "# === Main Loop Over Folds ===\n",
    "for fold_id in range(1, n_folds + 1):\n",
    "    print(f\"\\n=== Processing Fold {fold_id} ===\")\n",
    "\n",
    "    # Load fold graph\n",
    "    graph_path = f\"{save_dir}/fold_{fold_id}_graph.pt\"\n",
    "    if not os.path.exists(graph_path):\n",
    "        print(f\"Graph not found: {graph_path}\")\n",
    "        continue\n",
    "    batch = torch.load(graph_path)\n",
    "    loader = DataLoader([batch], batch_size=1, shuffle=False)\n",
    "\n",
    "    # Load model\n",
    "    model_path = f\"{save_dir}/cell_type_model_fold_{fold_id}_best.pth\"\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Model not found: {model_path}\")\n",
    "        continue\n",
    "\n",
    "    model = GNN(\n",
    "        in_channels=batch.num_node_features,\n",
    "        hidden_channels=64,\n",
    "        out_channels=num_classes,\n",
    "        num_layers=5\n",
    "    ).to(device)\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize explainer\n",
    "    explainer = Explainer(\n",
    "        model=model,\n",
    "        algorithm=CaptumExplainer(attr_method),\n",
    "        explanation_type=\"model\",\n",
    "        node_mask_type=\"attributes\",\n",
    "        edge_mask_type=None,\n",
    "        model_config=dict(\n",
    "            mode='multiclass_classification',\n",
    "            task_level='node',\n",
    "            return_type='probs',\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    for batch_data in tqdm(loader, desc=f\"Fold {fold_id} Explanation\"):\n",
    "        batch_data = batch_data.to(device)\n",
    "\n",
    "        avg_all = calculate_average_explanations(explainer, batch_data, mask=None, n_iterations=1)\n",
    "        all_scores[\"all\"].append(avg_all)\n",
    "\n",
    "        if batch_data.test_mask.any():\n",
    "            avg_test = calculate_average_explanations(explainer, batch_data, mask=batch_data.test_mask, n_iterations=1)\n",
    "            all_scores[\"test\"].append(avg_test)\n",
    "\n",
    "# Save scores for all nodes\n",
    "scores_df_all = pd.DataFrame({\n",
    "    feature_labels[i]: [np.abs(s[i]) for s in all_scores[\"all\"]]\n",
    "    for i in range(len(feature_labels))\n",
    "})\n",
    "scores_df_all[\"Fold_ID\"] = list(range(1, len(all_scores[\"all\"]) + 1))\n",
    "scores_df_all.to_csv(f\"{save_dir}\\\\cell_type_model_{attr_method}_all_scores.csv\", index=False)\n",
    "\n",
    "# Save scores for test nodes\n",
    "if all_scores[\"test\"]:\n",
    "    scores_df_test = pd.DataFrame({\n",
    "        feature_labels[i]: [np.abs(s[i]) for s in all_scores[\"test\"]]\n",
    "        for i in range(len(feature_labels))\n",
    "    })\n",
    "    scores_df_test[\"Fold_ID\"] = list(range(1, len(all_scores[\"test\"]) + 1))\n",
    "    scores_df_test.to_csv(f\"{save_dir}\\\\cell_type_model_{attr_method}_test_scores.csv\", index=False)\n",
    "\n",
    "# Print summary\n",
    "print(\"✓ Feature importance scores saved for all and test nodes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f300259-e3d1-414c-97b7-6f037d5f41c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# === Experiment Setup ===\n",
    "save_dir = r\"results\\high_low_no\"\n",
    "load_dir = save_dir\n",
    "attr_method = 'IntegratedGradients'\n",
    "\n",
    "# === File Paths ===\n",
    "all_scores_file = f\"{load_dir}\\\\cell_type_model_{attr_method}_all_scores.csv\"\n",
    "test_scores_file = f\"{load_dir}\\\\cell_type_model_{attr_method}_test_scores.csv\"\n",
    "\n",
    "# === Load All-Nodes Scores ===\n",
    "if os.path.exists(all_scores_file):\n",
    "    scores_df_all = pd.read_csv(all_scores_file)\n",
    "    print(\"Loaded all-nodes scores CSV.\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"All-nodes scores file not found: {all_scores_file}\")\n",
    "\n",
    "# === Load Test-Nodes Scores (Optional) ===\n",
    "if os.path.exists(test_scores_file):\n",
    "    scores_df_test = pd.read_csv(test_scores_file)\n",
    "    print(\"Loaded test-nodes scores CSV.\")\n",
    "else:\n",
    "    print(\"Test-nodes scores file not found. Proceeding with only all-nodes scores.\")\n",
    "    scores_df_test = None\n",
    "\n",
    "# === Extract Feature Labels (exclude Fold_ID) ===\n",
    "feature_labels = [col for col in scores_df_all.columns if col != \"Fold_ID\"]\n",
    "\n",
    "# === Compute Averages Across Folds ===\n",
    "average_scores_all = scores_df_all[feature_labels].mean(axis=0).values\n",
    "scores_df_all = scores_df_all.drop(columns=[\"Fold_ID\"])\n",
    "\n",
    "if scores_df_test is not None:\n",
    "    average_scores_test = scores_df_test[feature_labels].mean(axis=0).values\n",
    "    scores_df_test = scores_df_test.drop(columns=[\"Fold_ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee286df3-e403-489d-abb1-6264c80261e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Prepare data for boxplot\n",
    "# Assume `all_model_scores` is a list of arrays containing feature importance scores for each model\n",
    "scores_array = np.array([np.abs(model_scores) for model_scores in scores_df_test.values])\n",
    "\n",
    "# Convert to DataFrame for easier plotting\n",
    "feature_labels = [c for c in adata.var_names if c.startswith(\"mz_\")]\n",
    "assert scores_array.shape[1] == len(feature_labels), \"Feature labels and score dimensions do not match!\"\n",
    "\n",
    "scores_df = pd.DataFrame(scores_array, columns=feature_labels)\n",
    "\n",
    "# Plot boxplot for all features (vertical orientation)\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.boxplot(data=scores_df, orient='v', color='skyblue')\n",
    "plt.title(\"Feature Importance Distribution Across Models\", fontsize=16)\n",
    "plt.xlabel(\"Features\", fontsize=12)\n",
    "plt.ylabel(\"Importance Score\", fontsize=12)\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45, fontsize=6, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbc7fdd-169b-49af-9722-9b446c6a1164",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from typing import Optional, List\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def visualize_feature_importance(\n",
    "    all_scores: List[np.ndarray],\n",
    "    labels: Optional[List[str]] = None,\n",
    "    top_k: Optional[int] = None,\n",
    "    save_path: Optional[str] = None,\n",
    "    individual_plots: bool = False,\n",
    "    individual_save_dir: Optional[str] = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualize aggregated feature importance scores (mean and standard deviation) across multiple models\n",
    "    and optionally plot individual feature importance scores for each model.\n",
    "    \n",
    "    Parameters:\n",
    "    - all_scores: List of arrays containing feature importance scores for each model.\n",
    "    - labels: Optional list of feature labels (defaults to Feature_1, Feature_2, ...).\n",
    "    - top_k: Show only top_k features (optional).\n",
    "    - save_path: Path to save the aggregated plot (optional).\n",
    "    - individual_plots: Whether to generate individual plots for each model (default: False).\n",
    "    - individual_save_dir: Directory to save individual plots if `individual_plots` is True (optional).\n",
    "    \"\"\"\n",
    "    # Calculate mean and std of feature importance scores\n",
    "    scores_array = np.array(all_scores)\n",
    "    mean_scores = scores_array.mean(axis=0)\n",
    "    std_scores = scores_array.std(axis=0)\n",
    "\n",
    "    if labels is None:\n",
    "        labels = [f\"Feature_{i+1}\" for i in range(len(mean_scores))]  # Default labels\n",
    "\n",
    "    # Create a DataFrame for sorting and slicing\n",
    "    df = pd.DataFrame({\n",
    "        'mean_score': mean_scores,\n",
    "        'std_score': std_scores\n",
    "    }, index=labels)\n",
    "    df = df.sort_values('mean_score', ascending=False)  # Sort by mean score\n",
    "    df = df.round(decimals=3)  # Round for better display\n",
    "\n",
    "    # Select top_k features if specified\n",
    "    if top_k is not None:\n",
    "        df = df.head(top_k)\n",
    "\n",
    "    # Extract sorted features and their scores for plotting\n",
    "    sorted_features = df.index.tolist()\n",
    "    sorted_mean_scores = df['mean_score'].tolist()\n",
    "\n",
    "    # Plot aggregated feature importance\n",
    "    plt.figure(figsize=(14, 8))  # Wider figure for better x-label spacing\n",
    "    plt.bar(sorted_features, sorted_mean_scores, alpha=0.7, color=\"skyblue\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")  # Rotate and align x-axis labels\n",
    "    plt.title(\"Top Features - Aggregated Importance\")\n",
    "    plt.xlabel(\"Feature\")\n",
    "    plt.ylabel(\"Mean Importance\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save or display the aggregated plot\n",
    "    if save_path is not None:\n",
    "        plt.savefig(f\"{save_path}/cell_type_{attr_method}_feature_importance_aggregated.png\", bbox_inches=\"tight\")\n",
    "        print(f\"Aggregated feature importance plot saved to {save_path}\")\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "    # Generate individual plots for each model\n",
    "    if individual_plots:\n",
    "        for i, scores in enumerate(all_scores):\n",
    "            # Create individual DataFrame and sort by scores\n",
    "            individual_df = pd.DataFrame({'score': scores}, index=labels)\n",
    "            individual_df = individual_df.sort_values('score', ascending=False)\n",
    "\n",
    "            if top_k is not None:\n",
    "                individual_df = individual_df.head(top_k)\n",
    "\n",
    "            sorted_individual_features = individual_df.index.tolist()\n",
    "            sorted_individual_scores = individual_df['score'].tolist()\n",
    "\n",
    "            # Plot individual feature importance\n",
    "            plt.figure(figsize=(14, 8))  # Wider figure for better x-label spacing\n",
    "            plt.bar(sorted_individual_features, sorted_individual_scores, alpha=0.7, color=\"lightcoral\")\n",
    "            plt.xticks(rotation=45, ha=\"right\")  # Rotate and align x-axis labels\n",
    "            plt.title(f\"Top Features for Model {i+1}\")\n",
    "            plt.xlabel(\"Feature\")\n",
    "            plt.ylabel(\"Importance\")\n",
    "            plt.tight_layout()\n",
    "\n",
    "            if individual_save_dir:\n",
    "                plt.savefig(f\"{individual_save_dir}/cell_type_{attr_method}_feature_importance_model_{i+1}.png\", bbox_inches=\"tight\")\n",
    "            else:\n",
    "                plt.show()\n",
    "\n",
    "# Example Usage\n",
    "scores_list = [np.abs(model_scores) for model_scores in scores_df_test.values]\n",
    "feature_labels = [c for c in adata.var_names if c.startswith(\"mz_\")]\n",
    "\n",
    "# Visualize aggregated importance for top 20 features and save individual plots\n",
    "visualize_feature_importance(\n",
    "    all_scores=scores_list, \n",
    "    labels=feature_labels, \n",
    "    top_k=50,  # Adjust to display top 50 features,\n",
    "    save_path=save_dir,\n",
    "    individual_plots=True,\n",
    "    individual_save_dir=save_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4733d1-896d-4f33-ae40-51b3f918ebd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from typing import Optional, List\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 1. Short m/z label dictionary\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "mz_shortnames = {\n",
    "    'mz_699.4500': 'PA 34:1 (699.45 m/z)',\n",
    "    'mz_701.5500': 'PA 36:1 (701.55 m/z)',\n",
    "    'mz_719.5500': 'PE 34:0 (719.55 m/z)',\n",
    "    'mz_745.5500': 'PG 34:2 (745.55 m/z)',\n",
    "    'mz_747.4500': 'PG 34:1 (747.45 m/z)',\n",
    "    'mz_748.5500': 'PE 36:1 (748.55 m/z)',\n",
    "    'mz_762.5500': 'PE 38:6 (762.55 m/z)',\n",
    "    'mz_772.5500': 'PE 38:1 (772.55 m/z)',\n",
    "    'mz_790.5500': 'PS 36:1 (790.55 m/z)',\n",
    "    'mz_794.5500': 'PS 36:0 (794.55 m/z)',\n",
    "    'mz_880.6500': 'PI 38:4 (880.65 m/z)',\n",
    "    'mz_888.6500': 'ST C24:1 (888.65 m/z)',\n",
    "    'mz_889.6500': 'ST 42:2 (889.65 m/z)',\n",
    "    'mz_890.6500': 'ST C24:0 (890.65 m/z)',\n",
    "    'mz_905.6500': 'ST C24:0 (OH) (905.65 m/z)',\n",
    "}\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 2. Main visualization function\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "def visualize_feature_importance(\n",
    "    all_scores: List[np.ndarray],\n",
    "    labels: Optional[List[str]] = None,\n",
    "    top_k: Optional[int] = None,\n",
    "    save_path: Optional[str] = None,\n",
    "    individual_plots: bool = False,\n",
    "    individual_save_dir: Optional[str] = None,\n",
    "    attr_method: str = \"gnnexplainer\",\n",
    "    show_ranks: bool = True,\n",
    "    color_map: str = \"viridis\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualize aggregated and per-model feature importance scores with clean layout.\n",
    "    \"\"\"\n",
    "    scores_array = np.array(all_scores)\n",
    "    mean_scores = scores_array.mean(axis=0)\n",
    "    std_scores = scores_array.std(axis=0)\n",
    "\n",
    "    if labels is None:\n",
    "        labels = [f\"Feature_{i+1}\" for i in range(len(mean_scores))]\n",
    "\n",
    "    # Map m/z labels to short names (with m/z in parentheses)\n",
    "    labels = [mz_shortnames.get(lab, lab) for lab in labels]\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"mean_score\": mean_scores,\n",
    "        \"std_score\": std_scores\n",
    "    }, index=labels).sort_values(\"mean_score\", ascending=False)\n",
    "\n",
    "    if top_k:\n",
    "        df = df.head(top_k)\n",
    "\n",
    "    # === AGGREGATED PLOT === #\n",
    "    fig, ax = plt.subplots(figsize=(10, max(6, 0.3 * len(df))), constrained_layout=True)\n",
    "    cmap = plt.get_cmap(color_map)\n",
    "    norm = (df[\"mean_score\"] - df[\"mean_score\"].min()) / (df[\"mean_score\"].max() - df[\"mean_score\"].min())\n",
    "    colors = cmap(norm)\n",
    "\n",
    "    ax.barh(df.index[::-1], df[\"mean_score\"][::-1],\n",
    "             color=colors[::-1],\n",
    "            edgecolor='black', alpha=0.9)\n",
    "\n",
    "    ax.set_xlabel(\"Mean Importance Score\", fontsize=16)\n",
    "    plt.xticks(fontsize=16)\n",
    "    ax.set_title(f\"Top {len(df)} Lipids\", fontsize=18)\n",
    "\n",
    "    if show_ranks:\n",
    "        for i, (val, label) in enumerate(zip(df[\"mean_score\"][::-1], df.index[::-1])):\n",
    "            ax.text(val + 0.01, i, f\"{i+1}\", va='center', color='white', fontsize=16)\n",
    "\n",
    "    plt.yticks(fontsize=16)\n",
    "    ax.set_ylim(-0.5, len(df) - 0.5)\n",
    "\n",
    "    if save_path:\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        plt.savefig(f\"{save_path}/cell_type_{attr_method}_feature_importance_aggregated.png\",\n",
    "                    bbox_inches=\"tight\", pad_inches=0.0, dpi=600)\n",
    "        print(f\"[✓] Saved aggregated plot to {save_path}\")\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "    # === INDIVIDUAL PLOTS === #\n",
    "    if individual_plots:\n",
    "        os.makedirs(individual_save_dir, exist_ok=True)\n",
    "        for i, scores in enumerate(all_scores):\n",
    "            ind_df = pd.DataFrame({'score': scores}, index=labels).sort_values('score', ascending=False)\n",
    "            if top_k:\n",
    "                ind_df = ind_df.head(top_k)\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(10, max(6, 0.3 * len(ind_df))), constrained_layout=True)\n",
    "            color_vals = cmap((ind_df[\"score\"] - ind_df[\"score\"].min()) / (ind_df[\"score\"].max() - ind_df[\"score\"].min()))\n",
    "            ax.barh(ind_df.index[::-1], ind_df[\"score\"][::-1], color=color_vals[::-1],\n",
    "                    edgecolor='black', alpha=0.9)\n",
    "\n",
    "            ax.set_xlabel(\"Importance Score\", fontsize=16)\n",
    "            plt.xticks(fontsize=16)\n",
    "            ax.set_title(f\"Top {len(ind_df)} Lipids (Model {i+1})\", fontsize=18)\n",
    "\n",
    "            if show_ranks:\n",
    "                for j, (val, label) in enumerate(zip(ind_df[\"score\"][::-1], ind_df.index[::-1])):\n",
    "                    ax.text(val + 0.01, j, f\"{j+1}\", va='center', color='white', fontsize=16)\n",
    "\n",
    "            plt.yticks(fontsize=16)\n",
    "            ax.set_ylim(-0.5, len(ind_df) - 0.5)\n",
    "\n",
    "            plt.savefig(f\"{individual_save_dir}/cell_type_{attr_method}_feature_importance_model_{i+1}.png\",\n",
    "                        bbox_inches=\"tight\", pad_inches=0.0, dpi=600)\n",
    "            plt.show()\n",
    "            print(f\"[✓] Saved model {i+1} plot to {individual_save_dir}\")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 3. Run the function with your inputs\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "visualize_feature_importance(\n",
    "    all_scores=scores_list,\n",
    "    labels=feature_labels,\n",
    "    top_k=15,\n",
    "    save_path=save_dir,\n",
    "    individual_plots=True,\n",
    "    individual_save_dir=save_dir,\n",
    "    attr_method=attr_method,\n",
    "    show_ranks=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b930845d-5fb6-4ffe-8e64-98a645ff0752",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from kneed import KneeLocator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sort features by general importance\n",
    "sorted_indices = np.argsort(average_scores_test)[::-1]\n",
    "sorted_features = [feature_labels[i] for i in sorted_indices]\n",
    "sorted_importance = average_scores_test[sorted_indices]\n",
    "\n",
    "# Function to find all knee points\n",
    "def find_knee_points(x, y, max_knees=3, curve=\"convex\", direction=\"decreasing\"):\n",
    "    knees = []\n",
    "    remaining_x = x\n",
    "    remaining_y = y\n",
    "    \n",
    "    for _ in range(max_knees):\n",
    "        # Use KneeLocator to find the next knee point\n",
    "        knee_locator = KneeLocator(range(len(remaining_y)), remaining_y, curve=curve, direction=direction)\n",
    "        k = knee_locator.knee\n",
    "        \n",
    "        if k is not None:\n",
    "            knees.append((remaining_x[k], remaining_y[k]))  # Store the knee point\n",
    "            # Split data and continue searching\n",
    "            remaining_x = remaining_x[k + 1:]\n",
    "            remaining_y = remaining_y[k + 1:]\n",
    "            \n",
    "            if len(remaining_y) < 2:  # Stop if fewer than two points remain\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return knees\n",
    "\n",
    "# Find all knee points\n",
    "x_range = range(len(sorted_importance))\n",
    "knee_points = find_knee_points(x_range, sorted_importance, max_knees=5)\n",
    "\n",
    "# Get features corresponding to each knee\n",
    "knee_indices = [kp[0] for kp in knee_points]\n",
    "knee_features = [sorted_features[ki] for ki in knee_indices]\n",
    "knee_importance = [sorted_importance[ki] for ki in knee_indices]\n",
    "\n",
    "# Plot the sorted importance with all knee points\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1,len(x_range)+1), sorted_importance, label=\"Sorted Importance\", marker=\"o\")\n",
    "for ki in knee_indices:\n",
    "    plt.axvline(ki+1, color=\"red\", linestyle=\"--\", label=f\"Knee Point (k={ki+1})\")\n",
    "plt.xlabel(\"Metabolites\", fontsize=16)\n",
    "plt.ylabel(\"Importance\", fontsize=16)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.title(\"Sorted Importances of Metabolites\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.xlim([1,len(x_range)+1])\n",
    "plt.grid()\n",
    "plt.savefig(f\"{save_dir}/sorted_importance_with_cutoff.png\", dpi=600)\n",
    "plt.show()\n",
    "\n",
    "# Print knee points and features\n",
    "print(\"Knee points and corresponding features:\")\n",
    "for i, (feature, importance) in enumerate(zip(knee_features, knee_importance), start=1):\n",
    "    print(f\"Knee {i}: {feature} - Importance: {importance:.4f}\")\n",
    "\n",
    "np.save(os.path.join(save_dir,'sorted_features.npy'), sorted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c748963b-006d-4ef2-85b1-afdb0c0fdc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "knee_point = 15\n",
    "top_k_features = sorted_features[:knee_point]\n",
    "print(top_k_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1509af12-aee4-40e7-9609-a101f28002a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from scipy.stats import mode\n",
    "\n",
    "# === Parameters ===\n",
    "num_folds = 3\n",
    "num_thresholds = 9\n",
    "phenotype_to_barcodes = {}  # collect per fold\n",
    "phenotype_names_all = set()\n",
    "\n",
    "# === Helper Functions ===\n",
    "def compute_thresholds(data, num_thresholds):\n",
    "    quantiles = np.linspace(0, 1, num_thresholds + 2)[1:-1]\n",
    "    return {feature: data[feature].quantile(quantiles).values for feature in data.columns}\n",
    "\n",
    "def categorize_values(data, thresholds):\n",
    "    categorical_matrix = np.zeros(data.shape, dtype=int)\n",
    "    for i, feature in enumerate(data.columns):\n",
    "        for level, threshold in enumerate(thresholds[feature]):\n",
    "            categorical_matrix[:, i] += (data[feature].values > threshold).astype(int)\n",
    "    return categorical_matrix\n",
    "\n",
    "def plot_barcode_matrix(matrix, row_labels, col_labels, color_map, filename):\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    for i in range(matrix.shape[0]):\n",
    "        for j in range(matrix.shape[1]):\n",
    "            level = matrix[i, j]\n",
    "            ax.scatter(\n",
    "                j, i,\n",
    "                color=color_map[level],\n",
    "                marker='D',\n",
    "                s=160,\n",
    "                edgecolors=\"black\",\n",
    "                linewidth=0.6\n",
    "            )\n",
    "    ax.set_xticks(range(len(col_labels)))\n",
    "    ax.set_xticklabels(col_labels, rotation=45, ha='right', fontsize=14)\n",
    "    ax.set_yticks(np.arange(len(row_labels)))\n",
    "    ax.set_yticklabels(row_labels, fontsize=14)\n",
    "    ax.set_ylim(-0.5, len(row_labels) - 0.5)\n",
    "    ax.set_xlabel(\"Metabolite Features\", fontsize=16)\n",
    "    ax.set_ylabel(\"Cell Phenotypes\", fontsize=16)\n",
    "    ax.grid(True, linestyle=\"--\", linewidth=0.4, alpha=0.3)\n",
    "    ax.tick_params(axis='both', which='major', length=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=600, bbox_inches='tight', pad_inches=0.0)\n",
    "    plt.show()\n",
    "\n",
    "# === Color map setup ===\n",
    "'''unique_colors = list(mcolors.TABLEAU_COLORS.values()) + list(mcolors.XKCD_COLORS.values())\n",
    "color_list = unique_colors[:num_thresholds + 1]\n",
    "color_map = {i: color_list[i] for i in range(num_thresholds + 1)}'''\n",
    "\n",
    "color_cmap = plt.cm.get_cmap('tab20')\n",
    "color_list = [mcolors.to_hex(color_cmap(i)) for i in range(num_thresholds + 1)]\n",
    "color_map = {i: color_list[i] for i in range(num_thresholds + 1)}\n",
    "\n",
    "# === Loop through folds ===\n",
    "for fold_id in range(1, num_folds + 1):\n",
    "    graph_path = f\"{load_dir}/fold_{fold_id}_graph.pt\"\n",
    "    if not os.path.exists(graph_path):\n",
    "        continue\n",
    "\n",
    "    graph = torch.load(graph_path)\n",
    "    train_mask = graph.train_mask.cpu().numpy()\n",
    "\n",
    "    X_all = pd.DataFrame(graph.x.cpu().numpy(), columns=feature_labels)\n",
    "    X_train = X_all.loc[train_mask, top_k_features].reset_index(drop=True)\n",
    "    y_train = graph.y.cpu().numpy()[train_mask]\n",
    "    cell_types_train = label_encoder.inverse_transform(y_train)\n",
    "\n",
    "    thresholds = compute_thresholds(X_train, num_thresholds)\n",
    "\n",
    "    # Compute phenotype mean barcodes\n",
    "    thresholds_fold = {feat: thresholds[feat] for feat in top_k_features}\n",
    "    phenotype_means = []\n",
    "    phenotype_names = []\n",
    "\n",
    "    for phenotype in np.unique(cell_types_train):\n",
    "        subset = X_train[cell_types_train == phenotype]\n",
    "        mean_vals = subset.mean(axis=0).to_frame().T\n",
    "        barcode_row = categorize_values(mean_vals, thresholds_fold)[0]\n",
    "        phenotype_names_all.add(phenotype)\n",
    "\n",
    "        # Store barcode in per-phenotype list\n",
    "        phenotype_to_barcodes.setdefault(phenotype, []).append(barcode_row)\n",
    "\n",
    "        phenotype_means.append(barcode_row)\n",
    "        phenotype_names.append(phenotype)\n",
    "\n",
    "    barcode_matrix = np.vstack(phenotype_means)\n",
    "\n",
    "    # Plot fold barcode\n",
    "    plot_barcode_matrix(\n",
    "        matrix=barcode_matrix,\n",
    "        row_labels=phenotype_names,\n",
    "        col_labels=top_k_features,\n",
    "        color_map=color_map,\n",
    "        filename=f\"{save_dir}/barcode_matrix_train_fold_{fold_id}.png\"\n",
    "    )\n",
    "\n",
    "# === Compute final barcodes via majority vote ===\n",
    "phenotype_barcodes = {}  # final dict\n",
    "final_matrix = []\n",
    "final_phenotypes = sorted(phenotype_names_all)\n",
    "\n",
    "for phenotype in final_phenotypes:\n",
    "    barcode_stack = np.stack(phenotype_to_barcodes[phenotype])  # [num_folds, num_features]\n",
    "    voted_barcode = mode(barcode_stack, axis=0).mode.flatten()\n",
    "    phenotype_barcodes[phenotype] = voted_barcode\n",
    "    final_matrix.append(voted_barcode)\n",
    "\n",
    "# === Plot final consensus barcode ===\n",
    "final_matrix_np = np.vstack(final_matrix)\n",
    "plot_barcode_matrix(\n",
    "    matrix=final_matrix_np,\n",
    "    row_labels=final_phenotypes,\n",
    "    col_labels=top_k_features,\n",
    "    color_map=color_map,\n",
    "    filename=f\"{save_dir}/barcode_matrix_majority_vote.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074913b4-2f7f-4089-8e3b-a6556d68d085",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cell_group_color_dict = {\n",
    "    \"Astrocytes\": \"#1f77b4\",         # blue\n",
    "    \"Oligodendrocytes\": \"#2ca02c\",   # green\n",
    "    \"Neurons\": \"#d62728\",            # red\n",
    "    \"Microglia\": \"#9467bd\",          # purple\n",
    "    \"Endothelial cells\": \"#e377c2\",  # pink\n",
    "}\n",
    "\n",
    "# Stack barcode vectors\n",
    "barcode_matrix = np.vstack(list(phenotype_barcodes.values()))\n",
    "phenotype_labels = list(phenotype_barcodes.keys())\n",
    "\n",
    "# Compute pairwise cosine distances\n",
    "dist_matrix = squareform(pdist(barcode_matrix, metric='cosine'))\n",
    "\n",
    "# Plot heatmap\n",
    "sns.heatmap(dist_matrix, annot=True, xticklabels=phenotype_labels, yticklabels=phenotype_labels, cmap='viridis')\n",
    "plt.title(\"Pairwise Cosine Distance Between Phenotype Barcodes\")\n",
    "plt.show()\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "barcode_matrix = np.vstack(list(phenotype_barcodes.values()))\n",
    "phenotype_labels = list(phenotype_barcodes.keys())\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "barcode_2d = pca.fit_transform(barcode_matrix)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "for i, label in enumerate(phenotype_labels):\n",
    "    color = cell_group_color_dict.get(label, \"#000000\")\n",
    "    plt.scatter(barcode_2d[i, 0], barcode_2d[i, 1], label=label, color=color, s=100)\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"PCA of Phenotype Barcodes\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.axis('equal')\n",
    "plt.grid()\n",
    "plt.savefig(f\"{save_dir}/pca_phenotype_barcodes.png\", dpi=600, bbox_inches='tight', pad_inches=0.0)\n",
    "plt.show()\n",
    "\n",
    "import scipy.cluster.hierarchy as sch\n",
    "\n",
    "dists = pdist(barcode_matrix, metric='cosine')\n",
    "linkage = sch.linkage(dists, method='average')\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sch.dendrogram(linkage, labels=phenotype_labels, color_threshold=0, above_threshold_color='black')\n",
    "plt.title(\"Hierarchical Clustering of Phenotype Barcodes\")\n",
    "plt.ylabel(\"Cosine Distance\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.savefig(f\"{save_dir}/hierarchical_clustering_phenotype_barcodes.png\", dpi=600, bbox_inches='tight', pad_inches=0.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21df038-f963-4473-abae-4ed4b9ad8a00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.stats import mode\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# Step 1: Stack barcodes and get labels\n",
    "barcode_matrix = np.vstack(list(phenotype_barcodes.values()))\n",
    "phenotype_labels = list(phenotype_barcodes.keys())\n",
    "\n",
    "# Step 2: Compute pairwise distances\n",
    "dist_matrix = squareform(pdist(barcode_matrix, metric='cosine'))  # or 'hamming'\n",
    "\n",
    "# Step 3: Cluster similar barcodes\n",
    "clustering = AgglomerativeClustering(\n",
    "    n_clusters=None,\n",
    "    distance_threshold=0.01,\n",
    "    linkage='average'\n",
    ")\n",
    "cluster_labels = clustering.fit_predict(dist_matrix)\n",
    "\n",
    "# Step 4: Group phenotypes by cluster ID\n",
    "group_to_phenos = {}\n",
    "for pheno, group_id in zip(phenotype_labels, cluster_labels):\n",
    "    group_to_phenos.setdefault(group_id, []).append(pheno)\n",
    "\n",
    "# Step 5: Create readable group names\n",
    "grouped_barcodes = {}\n",
    "phenotype_to_group = {}\n",
    "\n",
    "for group_id, pheno_list in group_to_phenos.items():\n",
    "    group_name = \"/\".join(sorted(pheno_list))\n",
    "    barcodes = np.vstack([phenotype_barcodes[p] for p in pheno_list])\n",
    "    mean_barcode = np.round(barcodes.mean(axis=0)).astype(int)\n",
    "    grouped_barcodes[group_name] = mean_barcode\n",
    "\n",
    "    for pheno in pheno_list:\n",
    "        phenotype_to_group[pheno] = group_name\n",
    "\n",
    "# Optional preview\n",
    "print(\"Grouped Barcode Names:\")\n",
    "print(list(grouped_barcodes.keys()))\n",
    "\n",
    "print(\"\\nPhenotype to Group Mapping:\")\n",
    "print(phenotype_to_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25faf862-1874-4565-8e27-6c5d165bab4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import os\n",
    "\n",
    "mz_shortnames = {\n",
    "    'mz_699.4500': 'PA 34:1 (699.45 m/z)',\n",
    "    'mz_701.5500': 'PA 36:1 (701.55 m/z)',\n",
    "    'mz_719.5500': 'PE 34:0 (719.55 m/z)',\n",
    "    'mz_745.5500': 'PG 34:2 (745.55 m/z)',\n",
    "    'mz_747.4500': 'PG 34:1 (747.45 m/z)',\n",
    "    'mz_748.5500': 'PE 36:1 (748.55 m/z)',\n",
    "    'mz_762.5500': 'PE 38:6 (762.55 m/z)',\n",
    "    'mz_772.5500': 'PE 38:1 (772.55 m/z)',\n",
    "    'mz_790.5500': 'PS 36:1 (790.55 m/z)',\n",
    "    'mz_794.5500': 'PS 36:0 (794.55 m/z)',\n",
    "    'mz_880.6500': 'PI 38:4 (880.65 m/z)',\n",
    "    'mz_888.6500': 'ST C24:1 (888.65 m/z)',\n",
    "    'mz_889.6500': 'ST 42:2 (889.65 m/z)',\n",
    "    'mz_890.6500': 'ST C24:0 (890.65 m/z)',\n",
    "    'mz_905.6500': 'ST C24:0 (OH) (905.65 m/z)',\n",
    "}\n",
    "\n",
    "col_labels_short = [mz_shortnames.get(mz, mz) for mz in top_k_features]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1.  Mean barcode per merged group\n",
    "# ------------------------------------------------------------\n",
    "grouped_barcodes = {}\n",
    "for gid, phenos in group_to_phenos.items():\n",
    "    barcodes      = np.vstack([phenotype_barcodes[p] for p in phenos])\n",
    "    mean_barcode  = np.round(barcodes.mean(axis=0)).astype(int)\n",
    "    grouped_name  = \"/\".join(sorted(phenos))       # e.g. \"Myeloid Cells/T Cells\"\n",
    "    grouped_barcodes[grouped_name] = mean_barcode\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2.  Colour map (0-num_thresholds discrete levels)\n",
    "# ------------------------------------------------------------\n",
    "'''unique_colors = list(mcolors.TABLEAU_COLORS.values()) + list(mcolors.XKCD_COLORS.values())\n",
    "color_list = unique_colors[:num_thresholds + 1]\n",
    "color_map = {i: color_list[i] for i in range(num_thresholds + 1)}'''\n",
    "\n",
    "color_cmap = plt.cm.get_cmap('tab20')\n",
    "color_list = [mcolors.to_hex(color_cmap(i)) for i in range(num_thresholds + 1)]\n",
    "color_map = {i: color_list[i] for i in range(num_thresholds + 1)}\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3.  Barcode matrix + labels\n",
    "# ------------------------------------------------------------\n",
    "group_labels   = list(grouped_barcodes.keys())\n",
    "barcode_matrix = np.vstack([grouped_barcodes[g] for g in group_labels])\n",
    "\n",
    "#  ── wrap Y-tick labels: “A/B/C”  →  stacked text ───────────\n",
    "wrapped_labels = [lbl.replace(\"/\", \"\\n\") for lbl in group_labels]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4.  Plot\n",
    "# ------------------------------------------------------------\n",
    "def plot_barcode_matrix(matrix, row_labels, col_labels, color_map, filename):\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "    for r in range(matrix.shape[0]):\n",
    "        for c in range(matrix.shape[1]):\n",
    "            lvl = matrix[r, c]\n",
    "            ax.scatter(\n",
    "                c, r,\n",
    "                color=color_map.get(lvl, \"black\"),\n",
    "                marker=\"D\",\n",
    "                s=160,\n",
    "                edgecolors=\"black\",\n",
    "                linewidth=0.6,\n",
    "            )\n",
    "\n",
    "    ax.set_xticks(range(len(col_labels)))\n",
    "    ax.set_xticklabels(col_labels, rotation=45, ha=\"right\", fontsize=14)\n",
    "\n",
    "    ax.set_yticks(np.arange(len(row_labels)))\n",
    "    ax.set_yticklabels(row_labels, fontsize=14, va=\"center\")\n",
    "\n",
    "    ax.set_xlim(-0.5, len(col_labels) - 0.5)\n",
    "    ax.set_ylim(-0.5, len(row_labels) - 0.5)\n",
    "\n",
    "    ax.grid(True, linestyle=\"--\", linewidth=0.4, alpha=0.3)\n",
    "    ax.tick_params(axis=\"both\", which=\"major\", length=0)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=600, bbox_inches=\"tight\", pad_inches=0.02)\n",
    "    plt.show()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5.  Save figure\n",
    "# ------------------------------------------------------------\n",
    "output_path = os.path.join(save_dir, \"barcode_matrix_grouped.png\")\n",
    "plot_barcode_matrix(\n",
    "    matrix=barcode_matrix,\n",
    "    row_labels=wrapped_labels,      # <- stacked Y-labels\n",
    "    col_labels=col_labels_short,\n",
    "    color_map=color_map,\n",
    "    filename=output_path,\n",
    ")\n",
    "\n",
    "np.save(os.path.join(save_dir, f\"barcode_matrix_grouped.npy\"),barcode_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4752f06b-55b7-491f-8b71-12d0eea3da13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create diamond marker legend handles\n",
    "legend_handles = [\n",
    "    plt.Line2D([0], [0],\n",
    "               marker='D',\n",
    "               color='w',\n",
    "               markerfacecolor=color_map[i],\n",
    "               markeredgecolor='black',\n",
    "               markersize=10,\n",
    "               label=f\"Level {i + 1}\")\n",
    "    for i in range(num_thresholds + 1)\n",
    "][::-1]  # Reverse for top-down order\n",
    "\n",
    "# Compact vertical layout\n",
    "fig, ax = plt.subplots(figsize=(2.2, len(legend_handles) * 0.45))\n",
    "ax.axis('off')\n",
    "\n",
    "ax.legend(\n",
    "    handles=legend_handles,\n",
    "    loc='center',\n",
    "    fontsize=12,\n",
    "    frameon=False,\n",
    "    handletextpad=0.5,\n",
    "    labelspacing=0.3,\n",
    "    borderpad=0.1,\n",
    "    title=\"Barcode Level\",\n",
    "    title_fontsize=13\n",
    ")\n",
    "\n",
    "plt.savefig(f\"{save_dir}/scatter_barcode_legend.png\", dpi=600, bbox_inches='tight', pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefffc44-28ea-4878-ae33-92187bc984d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "magic",
   "language": "python",
   "name": "magic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
